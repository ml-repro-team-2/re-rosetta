{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:32:05.618063Z","iopub.status.busy":"2024-01-22T17:32:05.617085Z","iopub.status.idle":"2024-01-22T17:32:05.623461Z","shell.execute_reply":"2024-01-22T17:32:05.622339Z","shell.execute_reply.started":"2024-01-22T17:32:05.618018Z"},"trusted":true},"outputs":[],"source":["# !pip install \n","# import torch.hubimport os\n","# import sys\n","# current = os.path.dirname(os.path.realpath(\"inversion-stylegan2.ipynb\"))\n","# parent = os.path.dirname(current)\n","# sys.path.append(parent)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:32:05.625647Z","iopub.status.busy":"2024-01-22T17:32:05.625309Z","iopub.status.idle":"2024-01-22T17:32:09.311124Z","shell.execute_reply":"2024-01-22T17:32:09.309951Z","shell.execute_reply.started":"2024-01-22T17:32:05.62562Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/yossigandelsman/rosetta_neurons.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:32:09.313357Z","iopub.status.busy":"2024-01-22T17:32:09.312834Z","iopub.status.idle":"2024-01-22T17:32:09.323199Z","shell.execute_reply":"2024-01-22T17:32:09.322213Z","shell.execute_reply.started":"2024-01-22T17:32:09.313318Z"},"trusted":true},"outputs":[],"source":["%cd rosetta_neurons"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:32:09.324994Z","iopub.status.busy":"2024-01-22T17:32:09.324598Z","iopub.status.idle":"2024-01-22T17:32:20.11129Z","shell.execute_reply":"2024-01-22T17:32:20.110223Z","shell.execute_reply.started":"2024-01-22T17:32:09.324964Z"},"trusted":true},"outputs":[],"source":["import torch\n","device = torch.device('cuda:0')\n","dino = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50').to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:32:20.114814Z","iopub.status.busy":"2024-01-22T17:32:20.114337Z","iopub.status.idle":"2024-01-22T17:35:27.293932Z","shell.execute_reply":"2024-01-22T17:35:27.292679Z","shell.execute_reply.started":"2024-01-22T17:32:20.114781Z"},"trusted":true},"outputs":[],"source":["#@title Requirements\n","!pip install -r requirements.txt\n","!pip install transformers\n","!pip install openai-clip\n","!pip install einops\n","!pip install pytorch_pretrained_biggan\n","!pip install Ninja\n","!pip install timm==0.4.12\n","!pip install dill"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:35:27.296364Z","iopub.status.busy":"2024-01-22T17:35:27.295922Z","iopub.status.idle":"2024-01-22T17:36:55.405428Z","shell.execute_reply":"2024-01-22T17:36:55.404341Z","shell.execute_reply.started":"2024-01-22T17:35:27.296316Z"},"trusted":true},"outputs":[],"source":["from transformers import CLIPProcessor, CLIPModel\n","import torch\n","import torchvision\n","from torchvision.models import resnet50\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import clip\n","from PIL import Image\n","import requests\n","import torch.hub\n","import time\n","import pickle\n","import math\n","\n","from match_utils import matching, stats, proggan, nethook, dataset, loading, plotting, layers, models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:36:55.407539Z","iopub.status.busy":"2024-01-22T17:36:55.407115Z","iopub.status.idle":"2024-01-22T17:37:13.28416Z","shell.execute_reply":"2024-01-22T17:37:13.282789Z","shell.execute_reply.started":"2024-01-22T17:36:55.407498Z"},"trusted":true},"outputs":[],"source":["!pip install gdown==4.6.3\n","!gdown \"https://drive.google.com/uc?export=download&id=1nB5RQPrWRfcLI7yHhKKkf4gjxrJW7HCj\" -O 'stylegan2-cat-config-f.pt'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:13.286511Z","iopub.status.busy":"2024-01-22T17:37:13.286102Z","iopub.status.idle":"2024-01-22T17:37:14.34524Z","shell.execute_reply":"2024-01-22T17:37:14.344049Z","shell.execute_reply.started":"2024-01-22T17:37:13.286476Z"},"trusted":true},"outputs":[],"source":["from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n","                                       save_as_images, display_in_terminal)\n","\n","\n","gan, gan_layers = models.load_gan('stylegan2-lsun_cat', path='/kaggle/working/rosetta_neurons/', device=device)    \n","dino, dino_layers = models.load_discr('dino', path='models/', device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:14.347159Z","iopub.status.busy":"2024-01-22T17:37:14.346765Z","iopub.status.idle":"2024-01-22T17:37:15.280508Z","shell.execute_reply":"2024-01-22T17:37:15.279454Z","shell.execute_reply.started":"2024-01-22T17:37:14.347129Z"},"trusted":true},"outputs":[],"source":["    ganlayers, dinolayers = layers.get_layers(gan,gan_layers, dino, dino_layers,\"stylegan2-lsun_cat\", \"dino\", device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:15.282714Z","iopub.status.busy":"2024-01-22T17:37:15.282035Z","iopub.status.idle":"2024-01-22T17:37:16.117134Z","shell.execute_reply":"2024-01-22T17:37:16.116037Z","shell.execute_reply.started":"2024-01-22T17:37:15.282676Z"},"trusted":true},"outputs":[],"source":["import os\n","table, gan_stats, dino_stats = loading.load_stats(\"/kaggle/input/style-gan2-lsun-cat/rosetta_neurons/matches/stylegan2-lsun_cat/dino\", \n","                                                  device)\n","\n","save_path = \"/kaggle/working/rosetta_neurons/inversion_images_stylegan2/\"\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Best Buddies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.119227Z","iopub.status.busy":"2024-01-22T17:37:16.118905Z","iopub.status.idle":"2024-01-22T17:37:16.141632Z","shell.execute_reply":"2024-01-22T17:37:16.140556Z","shell.execute_reply.started":"2024-01-22T17:37:16.119201Z"},"trusted":true},"outputs":[],"source":["match_scores,_ = torch.max(table,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.143319Z","iopub.status.busy":"2024-01-22T17:37:16.143008Z","iopub.status.idle":"2024-01-22T17:37:16.162155Z","shell.execute_reply":"2024-01-22T17:37:16.160946Z","shell.execute_reply.started":"2024-01-22T17:37:16.143293Z"},"trusted":true},"outputs":[],"source":["gan_matches = torch.argmax(table,1)\n","dino_matches = torch.argmax(table,0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.164337Z","iopub.status.busy":"2024-01-22T17:37:16.163661Z","iopub.status.idle":"2024-01-22T17:37:16.353065Z","shell.execute_reply":"2024-01-22T17:37:16.352013Z","shell.execute_reply.started":"2024-01-22T17:37:16.164305Z"},"trusted":true},"outputs":[],"source":["perfect_matches = []\n","perfect_match_scores = []\n","dino_perfect_matches = []\n","num_perfect_matches = 0 \n","for i in range(table.shape[0]):\n","    gan_match = gan_matches[i].item()\n","    dino_match = dino_matches[gan_match].item()\n","    if dino_match == i:\n","        #print(i)\n","        num_perfect_matches+=1\n","        perfect_matches.append(i)\n","        dino_perfect_matches.append(gan_match)\n","        perfect_match_scores.append(match_scores[i])\n","        \n","print(num_perfect_matches)\n","print(num_perfect_matches/table.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.360261Z","iopub.status.busy":"2024-01-22T17:37:16.359851Z","iopub.status.idle":"2024-01-22T17:37:16.367007Z","shell.execute_reply":"2024-01-22T17:37:16.365817Z","shell.execute_reply.started":"2024-01-22T17:37:16.36023Z"},"trusted":true},"outputs":[],"source":["gan = nethook.InstrumentedModel(gan)\n","gan.retain_layers(gan_layers, detach = False)\n","\n","dino = nethook.InstrumentedModel(dino)\n","dino.retain_layers(dino_layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.368677Z","iopub.status.busy":"2024-01-22T17:37:16.368345Z","iopub.status.idle":"2024-01-22T17:37:16.395349Z","shell.execute_reply":"2024-01-22T17:37:16.394252Z","shell.execute_reply.started":"2024-01-22T17:37:16.36865Z"},"trusted":true},"outputs":[],"source":["for i, unit in enumerate(perfect_matches):\n","    perfect_matches[i] = layers.find_act(perfect_matches[i], ganlayers)#,all_gan_layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.397177Z","iopub.status.busy":"2024-01-22T17:37:16.396776Z","iopub.status.idle":"2024-01-22T17:37:16.40719Z","shell.execute_reply":"2024-01-22T17:37:16.406183Z","shell.execute_reply.started":"2024-01-22T17:37:16.397147Z"},"trusted":true},"outputs":[],"source":["for i, unit in enumerate(dino_perfect_matches):\n","    dino_perfect_matches[i] = layers.find_act(dino_perfect_matches[i], dinolayers)#,all_dino_layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.409241Z","iopub.status.busy":"2024-01-22T17:37:16.408808Z","iopub.status.idle":"2024-01-22T17:37:16.419529Z","shell.execute_reply":"2024-01-22T17:37:16.418524Z","shell.execute_reply.started":"2024-01-22T17:37:16.409211Z"},"trusted":true},"outputs":[],"source":["from scipy.stats import truncnorm\n","def truncate_noise(size, truncation):\n","    '''\n","    Function for creating truncated noise vectors: Given the dimensions (n_samples, z_dim)\n","    and truncation value, creates a tensor of that shape filled with random\n","    numbers from the truncated normal distribution.\n","    Parameters:\n","        n_samples: the number of samples to generate, a scalar\n","        z_dim: the dimension of the noise vector, a scalar\n","        truncation: the truncation value, a non-negative scalar\n","    '''\n","    \n","    truncated_noise = truncnorm.rvs(-1*truncation, truncation, size=size)\n","    \n","    return torch.Tensor(truncated_noise)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.421214Z","iopub.status.busy":"2024-01-22T17:37:16.4209Z","iopub.status.idle":"2024-01-22T17:37:16.441583Z","shell.execute_reply":"2024-01-22T17:37:16.440395Z","shell.execute_reply.started":"2024-01-22T17:37:16.421189Z"},"trusted":true},"outputs":[],"source":["z1 = truncate_noise((1,512), 1).to(device)#\n","from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.443958Z","iopub.status.busy":"2024-01-22T17:37:16.443109Z","iopub.status.idle":"2024-01-22T17:37:16.458266Z","shell.execute_reply":"2024-01-22T17:37:16.457091Z","shell.execute_reply.started":"2024-01-22T17:37:16.443907Z"},"trusted":true},"outputs":[],"source":["z = Variable(z1.clone(), requires_grad=True)\n","\n","with torch.no_grad():\n","    mean_latent = gan.model.mean_latent(4096)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.460074Z","iopub.status.busy":"2024-01-22T17:37:16.459722Z","iopub.status.idle":"2024-01-22T17:37:16.465722Z","shell.execute_reply":"2024-01-22T17:37:16.464395Z","shell.execute_reply.started":"2024-01-22T17:37:16.460039Z"},"trusted":true},"outputs":[],"source":["reg = torch.zeros((1,512)).to(device).detach()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.46724Z","iopub.status.busy":"2024-01-22T17:37:16.466915Z","iopub.status.idle":"2024-01-22T17:37:16.477289Z","shell.execute_reply":"2024-01-22T17:37:16.476355Z","shell.execute_reply.started":"2024-01-22T17:37:16.467212Z"},"trusted":true},"outputs":[],"source":["def show_gan_im(gan_im):\n","    im = (gan_im+1)/2\n","    im = torch.permute(im[0],(1,2,0)).detach().cpu()\n","    plt.imshow(im)\n","    plt.show()\n","    #plt.savefig( \"cat1.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.478859Z","iopub.status.busy":"2024-01-22T17:37:16.47857Z","iopub.status.idle":"2024-01-22T17:37:16.487852Z","shell.execute_reply":"2024-01-22T17:37:16.486931Z","shell.execute_reply.started":"2024-01-22T17:37:16.478834Z"},"trusted":true},"outputs":[],"source":["c_dataset = []\n","for iii in range(1):\n","    c_dataset.append(mean_latent)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.489534Z","iopub.status.busy":"2024-01-22T17:37:16.489222Z","iopub.status.idle":"2024-01-22T17:37:16.506467Z","shell.execute_reply":"2024-01-22T17:37:16.505471Z","shell.execute_reply.started":"2024-01-22T17:37:16.489508Z"},"trusted":true},"outputs":[],"source":["c=gan.model.mean_latent(4096).view(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.5085Z","iopub.status.busy":"2024-01-22T17:37:16.508146Z","iopub.status.idle":"2024-01-22T17:37:16.514219Z","shell.execute_reply":"2024-01-22T17:37:16.513046Z","shell.execute_reply.started":"2024-01-22T17:37:16.508459Z"},"trusted":true},"outputs":[],"source":["print(c.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.516145Z","iopub.status.busy":"2024-01-22T17:37:16.515732Z","iopub.status.idle":"2024-01-22T17:37:16.940561Z","shell.execute_reply":"2024-01-22T17:37:16.939432Z","shell.execute_reply.started":"2024-01-22T17:37:16.516108Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["img, _  = gan([z], 0.7, c)\n","print(img.shape)\n","show_gan_im(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:16.942215Z","iopub.status.busy":"2024-01-22T17:37:16.941885Z","iopub.status.idle":"2024-01-22T17:37:17.093825Z","shell.execute_reply":"2024-01-22T17:37:17.092693Z","shell.execute_reply.started":"2024-01-22T17:37:16.942187Z"},"trusted":true},"outputs":[],"source":["#real_im = Image.open(\"/home/amildravid/bigGAN-DINO_swap/val_im/ILSVRC2012_val_00028617-_1_.jpg\")\n","#real_im = Image.open(\"/home/amildravid/bigGAN-DINO_swap/golden_retriever/real/ILSVRC2012_val_00001112.jpg\")\n","#real_im = Image.open(\"/home/amildravid/bigActivation_Matching/val_im/ILSVRC2012_val_00006981.jpg\")\n","real_im = Image.open(\"/kaggle/input/trial-good/download.jpg\")\n","#real_im = Image.open(\"/home/amildravid/bigGAN-DINO_swap/golden_retriever/sketch/sketch_7.jpg\")\n","real_im"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:17.095609Z","iopub.status.busy":"2024-01-22T17:37:17.095261Z","iopub.status.idle":"2024-01-22T17:37:19.280248Z","shell.execute_reply":"2024-01-22T17:37:19.27863Z","shell.execute_reply.started":"2024-01-22T17:37:17.09558Z"},"trusted":true},"outputs":[],"source":["!mkdir -p imgs/dir0\n","!mkdir -p imgs/dir1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:19.282404Z","iopub.status.busy":"2024-01-22T17:37:19.282071Z","iopub.status.idle":"2024-01-22T17:37:19.332311Z","shell.execute_reply":"2024-01-22T17:37:19.331221Z","shell.execute_reply.started":"2024-01-22T17:37:19.282373Z"},"trusted":true},"outputs":[],"source":["real_im = torchvision.transforms.ToTensor()(real_im).unsqueeze(0).to(device)\n","#real_im = torchvision.transforms.RandomResizedCrop(256)(real_im)\n","real_im = torch.nn.functional.interpolate(real_im, size = (256,256), mode = \"bicubic\")\n","dino_real_im = torch.nn.functional.interpolate(real_im, size = (256,256), mode = \"bicubic\")\n","dino_real_im = torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(dino_real_im)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:19.334028Z","iopub.status.busy":"2024-01-22T17:37:19.333667Z","iopub.status.idle":"2024-01-22T17:37:20.405695Z","shell.execute_reply":"2024-01-22T17:37:20.404264Z","shell.execute_reply.started":"2024-01-22T17:37:19.333999Z"},"trusted":true},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:20.408019Z","iopub.status.busy":"2024-01-22T17:37:20.407619Z","iopub.status.idle":"2024-01-22T17:37:20.712814Z","shell.execute_reply":"2024-01-22T17:37:20.711595Z","shell.execute_reply.started":"2024-01-22T17:37:20.407983Z"},"trusted":true},"outputs":[],"source":["plt.imshow(torch.permute(real_im[0], (1,2,0)).cpu())\n","plt.axis('off')\n","plt.savefig( \"imgs/dir0/image_1.jpg\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:20.714846Z","iopub.status.busy":"2024-01-22T17:37:20.7144Z","iopub.status.idle":"2024-01-22T17:37:20.785966Z","shell.execute_reply":"2024-01-22T17:37:20.785067Z","shell.execute_reply.started":"2024-01-22T17:37:20.714801Z"},"trusted":true},"outputs":[],"source":["dino(dino_real_im)\n","dino_activs =  matching.store_activs(dino, dino_layers)\n","#normalize\n","eps = 0.00001\n","for i,_ in enumerate(dino_activs):\n","    dino_activs[i] = (dino_activs[i]-dino_stats[i][0])/(dino_stats[i][1]+eps)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:20.787736Z","iopub.status.busy":"2024-01-22T17:37:20.78736Z","iopub.status.idle":"2024-01-22T17:37:20.797511Z","shell.execute_reply":"2024-01-22T17:37:20.796073Z","shell.execute_reply.started":"2024-01-22T17:37:20.787706Z"},"trusted":true},"outputs":[],"source":["dino_perfect_activs = []\n","for idx in dino_perfect_matches:\n","    dino_perfect_activs.append(dino_activs[idx[0]][:,idx[1],:,:].unsqueeze(0))"]},{"cell_type":"markdown","metadata":{},"source":["### Pixel Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:20.799335Z","iopub.status.busy":"2024-01-22T17:37:20.79898Z","iopub.status.idle":"2024-01-22T17:37:20.810145Z","shell.execute_reply":"2024-01-22T17:37:20.80901Z","shell.execute_reply.started":"2024-01-22T17:37:20.799303Z"},"trusted":true},"outputs":[],"source":["optim = torch.optim.Adam([z], lr=0.01, betas=(0.5, 0.999))  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:20.812188Z","iopub.status.busy":"2024-01-22T17:37:20.811725Z","iopub.status.idle":"2024-01-22T17:37:35.566917Z","shell.execute_reply":"2024-01-22T17:37:35.565775Z","shell.execute_reply.started":"2024-01-22T17:37:20.812147Z"},"trusted":true},"outputs":[],"source":["for epoch in range(0,200):\n","    \n","    optim.zero_grad()\n","    sample,_ = gan([z],0.7,c)\n","    im = (sample+1)/2\n","    if(epoch%20==0):\n","        print(im.shape)\n","    \n","    loss = torch.mean((im-real_im)**2)\n","    \n","    \n","    \n","    if(epoch%20==0):\n","        print(\"E:\", epoch+1, \"loss:\", loss.item())\n","    loss.backward()\n","    optim.step()\n","    if(epoch%20==0):\n","        show_gan_im(sample)\n","    \n","    \n","    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n","    im = (im+1)/2\n","    \n","    \n","    if epoch<=9:\n","        file_name = \"00\"+str(epoch)+\".jpg\"\n","    elif epoch<=99:\n","        file_name = \"0\"+str(epoch)+\".jpg\"\n","    else: \n","        file_name = str(epoch)+\".jpg\"\n","   # plt.imsave(save_path+file_name, im)  \n","plt.imshow(im)\n","plt.axis('off')\n","plt.savefig( f\"pixel_loss_{file_name}\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Activation Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:35.569079Z","iopub.status.busy":"2024-01-22T17:37:35.568617Z","iopub.status.idle":"2024-01-22T17:37:35.575604Z","shell.execute_reply":"2024-01-22T17:37:35.574368Z","shell.execute_reply.started":"2024-01-22T17:37:35.569039Z"},"trusted":true},"outputs":[],"source":["optim = torch.optim.Adam([z], lr=0.01, betas=(0.5, 0.999))  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:37:35.577455Z","iopub.status.busy":"2024-01-22T17:37:35.577106Z","iopub.status.idle":"2024-01-22T17:38:20.106008Z","shell.execute_reply":"2024-01-22T17:38:20.104933Z","shell.execute_reply.started":"2024-01-22T17:37:35.577379Z"},"trusted":true},"outputs":[],"source":["for epoch in range(0,200):\n","    \n","    optim.zero_grad()\n","    sample,_ = gan([z],0.7,c)\n","    \n","    \n","    \n","    gan_activs = matching.store_activs(gan, gan_layers)\n","    \n","    \n","    #normalize all activations\n","    eps = 0.00001\n","    for i,_ in enumerate(gan_activs):\n","        gan_activs[i] = (gan_activs[i]-gan_stats[i][0])/(gan_stats[i][1]+eps)\n","        \n","    \n","    gan_perfect_activs = []\n","    for idx in perfect_matches:\n","        gan_perfect_activs.append(gan_activs[idx[0]][:,idx[1],:,:])\n","    \n","    \n","    loss = 0\n","    losses = []\n","    for i, _ in enumerate(gan_perfect_activs): \n","        map_size = max((gan_perfect_activs[i].shape[1], dino_perfect_activs[i].shape[1]))\n","        gan_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(gan_perfect_activs[i].unsqueeze(0))\n","        dino_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(dino_perfect_activs[i])   \n","        #loss += torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)/(map_size**2)\n","        prod = torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)\n","        div1 = torch.sum(gan_activ_new**2)\n","        div2 = torch.sum(dino_activ_new**2)\n","        corr = prod/torch.sqrt(div1*div2)\n","        loss += corr\n","        losses.append(corr)\n","        #loss += torch.mean((gan_activ_new-dino_activ_new)**2)\n","        \n","        \n","        \n","    loss *= -1 \n","    #regularization = 50*torch.mean((z-reg)**2)\n","    #loss +=  regularization\n","    if(epoch%20==0):\n","        print(\"E:\", epoch+1, \"loss:\", loss.item())\n","    loss.backward()\n","    optim.step()\n","    if(epoch%20==0):\n","        show_gan_im(sample)\n","    im = (sample+1)/2\n","    \n","    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n","    im = (im+1)/2\n","    \n","    \n","    if epoch<=9:\n","        file_name = \"00\"+str(epoch)+\".jpg\"\n","    elif epoch<=99:\n","        file_name = \"0\"+str(epoch)+\".jpg\"\n","    else: \n","        file_name = str(epoch)+\".jpg\"\n","    \n","    #plt.imsave(save_path+file_name, im)\n","plt.imshow(im)\n","plt.axis('off')\n","plt.savefig( f\"activation_loss_{file_name}\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Both Losses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:38:20.107962Z","iopub.status.busy":"2024-01-22T17:38:20.107571Z","iopub.status.idle":"2024-01-22T17:38:20.113655Z","shell.execute_reply":"2024-01-22T17:38:20.112377Z","shell.execute_reply.started":"2024-01-22T17:38:20.107924Z"},"trusted":true},"outputs":[],"source":["optim = torch.optim.Adam([z], lr=0.01, betas=(0.5, 0.999))  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:38:20.115434Z","iopub.status.busy":"2024-01-22T17:38:20.115111Z","iopub.status.idle":"2024-01-22T17:39:04.799068Z","shell.execute_reply":"2024-01-22T17:39:04.797938Z","shell.execute_reply.started":"2024-01-22T17:38:20.115406Z"},"trusted":true},"outputs":[],"source":["for epoch in range(0,200):\n","    \n","    optim.zero_grad()\n","    sample,_ = gan([z],0.7,c)\n","    \n","    im = (sample+1)/2\n","    pixel_loss = torch.mean((im-real_im)**2)\n","    \n","    \n","    if(epoch%20==0):\n","        print(pixel_loss)\n","    \n","    \n","    gan_activs = matching.store_activs(gan, gan_layers)\n","    \n","    \n","    #normalize all activations\n","    eps = 0.00001\n","    for i,_ in enumerate(gan_activs):\n","        gan_activs[i] = (gan_activs[i]-gan_stats[i][0])/(gan_stats[i][1]+eps)\n","        \n","    \n","    gan_perfect_activs = []\n","    for idx in perfect_matches:\n","        gan_perfect_activs.append(gan_activs[idx[0]][:,idx[1],:,:])\n","    \n","    \n","    loss = 0\n","    losses = []\n","    for i, _ in enumerate(gan_perfect_activs): \n","        map_size = max((gan_perfect_activs[i].shape[1], dino_perfect_activs[i].shape[1]))\n","        gan_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(gan_perfect_activs[i].unsqueeze(0))\n","        dino_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(dino_perfect_activs[i])   \n","        #loss += torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)/(map_size**2)\n","        prod = torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)\n","        div1 = torch.sum(gan_activ_new**2)\n","        div2 = torch.sum(dino_activ_new**2)\n","        corr = prod/torch.sqrt(div1*div2)\n","        loss += corr\n","        losses.append(corr)\n","        #loss += torch.mean((gan_activ_new-dino_activ_new)**2)\n","        \n","        \n","        \n","    loss *= -1 \n","    if(epoch%20==0):\n","        print(loss)\n","    loss += 100*pixel_loss\n","    \n","    \n","    #regularization = 100*torch.mean((z-reg)**2)\n","        #loss +=  regularization\n","    if(epoch%20==0):\n","        print(\"E:\", epoch+1, \"loss:\", loss.item())\n","    loss.backward()\n","    optim.step()\n","    if(epoch%20==0):\n","        show_gan_im(sample)\n","    im = (sample+1)/2\n","    \n","    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n","    im = (im+1)/2\n","    \n","    \n","    if epoch<=9:\n","        file_name = \"00\"+str(epoch)+\".jpg\"\n","    elif epoch<=99:\n","        file_name = \"0\"+str(epoch)+\".jpg\"\n","    else: \n","        file_name = str(epoch)+\".jpg\"\n","    \n","    #plt.imsave(save_path+file_name, im)\n","plt.imshow(im)\n","plt.axis('off')\n","plt.savefig( f\"imgs/dir1/image_1.jpg\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:39:04.800657Z","iopub.status.busy":"2024-01-22T17:39:04.800343Z","iopub.status.idle":"2024-01-22T17:39:19.06799Z","shell.execute_reply":"2024-01-22T17:39:19.06677Z","shell.execute_reply.started":"2024-01-22T17:39:04.800629Z"},"trusted":true},"outputs":[],"source":["!pip install lpips"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:39:19.070464Z","iopub.status.busy":"2024-01-22T17:39:19.069995Z","iopub.status.idle":"2024-01-22T17:39:20.1689Z","shell.execute_reply":"2024-01-22T17:39:20.167462Z","shell.execute_reply.started":"2024-01-22T17:39:19.07042Z"},"trusted":true},"outputs":[],"source":["!ls /opt/conda/lib/python3.10/site-packages/lpips"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:39:20.178385Z","iopub.status.busy":"2024-01-22T17:39:20.177604Z","iopub.status.idle":"2024-01-22T17:39:20.188798Z","shell.execute_reply":"2024-01-22T17:39:20.187701Z","shell.execute_reply.started":"2024-01-22T17:39:20.178346Z"},"trusted":true},"outputs":[],"source":["code = '''\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","import torch\n","# from torch.autograd import Variable\n","\n","from lpips.trainer import *\n","from lpips.lpips import *\n","\n","def normalize_tensor(in_feat,eps=1e-10):\n","    norm_factor = torch.sqrt(torch.sum(in_feat**2,dim=1,keepdim=True))\n","    return in_feat/(norm_factor+eps)\n","\n","def l2(p0, p1, range=255.):\n","    return .5*np.mean((p0 / range - p1 / range)**2)\n","\n","def psnr(p0, p1, peak=255.):\n","    return 10*np.log10(peak**2/np.mean((1.*p0-1.*p1)**2))\n","\n","def dssim(p0, p1, range=255.):\n","    from skimage.measure import compare_ssim\n","    return (1 - compare_ssim(p0, p1, data_range=range, multichannel=True)) / 2.\n","\n","def tensor2np(tensor_obj):\n","    # change dimension of a tensor object into a numpy array\n","    return tensor_obj[0].cpu().float().numpy().transpose((1,2,0))\n","\n","def np2tensor(np_obj):\n","     # change dimenion of np array into tensor array\n","    return torch.Tensor(np_obj[:, :, :, np.newaxis].transpose((3, 2, 0, 1)))\n","\n","def tensor2tensorlab(image_tensor,to_norm=True,mc_only=False):\n","    # image tensor to lab tensor\n","    from skimage import color\n","\n","    img = tensor2im(image_tensor)\n","    img_lab = color.rgb2lab(img)\n","    if(mc_only):\n","        img_lab[:,:,0] = img_lab[:,:,0]-50\n","    if(to_norm and not mc_only):\n","        img_lab[:,:,0] = img_lab[:,:,0]-50\n","        img_lab = img_lab/100.\n","\n","    return np2tensor(img_lab)\n","\n","def tensorlab2tensor(lab_tensor,return_inbnd=False):\n","    from skimage import color\n","    import warnings\n","    warnings.filterwarnings(\"ignore\")\n","\n","    lab = tensor2np(lab_tensor)*100.\n","    lab[:,:,0] = lab[:,:,0]+50\n","\n","    rgb_back = 255.*np.clip(color.lab2rgb(lab.astype('float')),0,1)\n","    if(return_inbnd):\n","        # convert back to lab, see if we match\n","        lab_back = color.rgb2lab(rgb_back.astype('uint8'))\n","        mask = 1.*np.isclose(lab_back,lab,atol=2.)\n","        mask = np2tensor(np.prod(mask,axis=2)[:,:,np.newaxis])\n","        return (im2tensor(rgb_back),mask)\n","    else:\n","        return im2tensor(rgb_back)\n","\n","def load_image(path):\n","    if(path[-3:] == 'dng'):\n","        import rawpy\n","        with rawpy.imread(path) as raw:\n","            img = raw.postprocess()\n","    elif(path[-3:]=='bmp' or path[-3:]=='jpg' or path[-3:]=='png' or path[-4:]=='jpeg'):\n","        import cv2\n","        return cv2.imread(path)[:,:,::-1]\n","    else:\n","        import matplotlib.pyplot as plt        \n","        img = (255*plt.imread(path)[:,:,:3]).astype('uint8')\n","\n","    return img\n","\n","def tensor2im(image_tensor, imtype=np.uint8, cent=1., factor=255./2.):\n","    image_numpy = image_tensor[0].cpu().float().numpy()\n","    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + cent) * factor\n","    return image_numpy.astype(imtype)\n","\n","def im2tensor(image, imtype=np.uint8, cent=1., factor=255./2.):\n","    return torch.Tensor((image / factor - cent)\n","                        [:, :, :, np.newaxis].transpose((3, 2, 0, 1)))\n","\n","def tensor2vec(vector_tensor):\n","    return vector_tensor.data.cpu().numpy()[:, :, 0, 0]\n","\n","\n","def voc_ap(rec, prec, use_07_metric=False):\n","    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n","    Compute VOC AP given precision and recall.\n","    If use_07_metric is true, uses the\n","    VOC 07 11 point method (default:False).\n","    \"\"\"\n","    if use_07_metric:\n","        # 11 point metric\n","        ap = 0.\n","        for t in np.arange(0., 1.1, 0.1):\n","            if np.sum(rec >= t) == 0:\n","                p = 0\n","            else:\n","                p = np.max(prec[rec >= t])\n","            ap = ap + p / 11.\n","    else:\n","        # correct AP calculation\n","        # first append sentinel values at the end\n","        mrec = np.concatenate(([0.], rec, [1.]))\n","        mpre = np.concatenate(([0.], prec, [0.]))\n","\n","        # compute the precision envelope\n","        for i in range(mpre.size - 1, 0, -1):\n","            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n","\n","        # to calculate area under PR curve, look for points\n","        # where X axis (recall) changes value\n","        i = np.where(mrec[1:] != mrec[:-1])[0]\n","\n","        # and sum (\\Delta recall) * prec\n","        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n","    return ap'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:39:20.190489Z","iopub.status.busy":"2024-01-22T17:39:20.190141Z","iopub.status.idle":"2024-01-22T17:39:20.205455Z","shell.execute_reply":"2024-01-22T17:39:20.204527Z","shell.execute_reply.started":"2024-01-22T17:39:20.190463Z"},"trusted":true},"outputs":[],"source":["with open(\"/opt/conda/lib/python3.10/site-packages/lpips/__init__.py\",\"w\") as f:\n","    f.write(code)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-22T17:39:20.207793Z","iopub.status.busy":"2024-01-22T17:39:20.20739Z","iopub.status.idle":"2024-01-22T17:39:26.970606Z","shell.execute_reply":"2024-01-22T17:39:26.9694Z","shell.execute_reply.started":"2024-01-22T17:39:20.207758Z"},"trusted":true},"outputs":[],"source":["!python calc_metrics.py  --dir0 /kaggle/working/rosetta_neurons/imgs/dir0 --dir1 /kaggle/working/rosetta_neurons/imgs/dir1 -o imgs_dist.txt --use_gpu --version 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":13371,"sourceId":18106,"sourceType":"datasetVersion"},{"datasetId":119698,"sourceId":791828,"sourceType":"datasetVersion"},{"datasetId":4316274,"isSourceIdPinned":true,"sourceId":7419169,"sourceType":"datasetVersion"},{"datasetId":4340773,"sourceId":7457215,"sourceType":"datasetVersion"},{"datasetId":4341041,"sourceId":7457608,"sourceType":"datasetVersion"},{"datasetId":4391200,"sourceId":7540891,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}

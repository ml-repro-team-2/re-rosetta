{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.hub\n",
    "import os\n",
    "import sys\n",
    "current = os.path.dirname(os.path.realpath(\"inversion-stylegan2.ipynb\"))\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:3')\n",
    "dino = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch.hub\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from match_utils import matching, stats, proggan, nethook, dataset, loading, plotting, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "\n",
    "gan, gan_layers = models.load_gan('stylegan2-lsun_horse', path='models/', device=device)    \n",
    "dino, dino_layers = models.load_discr('dino', path='models/', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganlayers, dinolayers = layers.get_layers(gan,gan_layers, dino, dino_layers,\"stylegan2-lsun_horse\", \"dino\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table, gan_stats, dino_stats = loading.load_stats(\"/home/yossi_gandelsman/gan_matches/results/results_dino_resnet_stylegan2-lsun_horse\", \n",
    "                                                  device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Buddies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_scores,_ = torch.max(table,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_matches = torch.argmax(table,1)\n",
    "dino_matches = torch.argmax(table,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_matches = []\n",
    "perfect_match_scores = []\n",
    "dino_perfect_matches = []\n",
    "num_perfect_matches = 0 \n",
    "for i in range(table.shape[0]):\n",
    "    gan_match = gan_matches[i].item()\n",
    "    dino_match = dino_matches[gan_match].item()\n",
    "    if dino_match == i:\n",
    "        #print(i)\n",
    "        num_perfect_matches+=1\n",
    "        perfect_matches.append(i)\n",
    "        dino_perfect_matches.append(gan_match)\n",
    "        perfect_match_scores.append(match_scores[i])\n",
    "        \n",
    "print(num_perfect_matches)\n",
    "print(num_perfect_matches/table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = nethook.InstrumentedModel(gan)\n",
    "gan.retain_layers(gan_layers, detach = False)\n",
    "\n",
    "dino = nethook.InstrumentedModel(dino)\n",
    "dino.retain_layers(dino_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, unit in enumerate(perfect_matches):\n",
    "    perfect_matches[i] = layers.find_act(perfect_matches[i], ganlayers)#,all_gan_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, unit in enumerate(dino_perfect_matches):\n",
    "    dino_perfect_matches[i] = layers.find_act(dino_perfect_matches[i], dinolayers)#,all_dino_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "def truncate_noise(size, truncation):\n",
    "    '''\n",
    "    Function for creating truncated noise vectors: Given the dimensions (n_samples, z_dim)\n",
    "    and truncation value, creates a tensor of that shape filled with random\n",
    "    numbers from the truncated normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        truncation: the truncation value, a non-negative scalar\n",
    "    '''\n",
    "    \n",
    "    truncated_noise = truncnorm.rvs(-1*truncation, truncation, size=size)\n",
    "    \n",
    "    return torch.Tensor(truncated_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = truncate_noise((1,512), 1).to(device)#\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(z1.clone(), requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    mean_latent = gan.model.mean_latent(4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = torch.zeros((1,512)).to(device).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gan_im(gan_im):\n",
    "    im = (gan_im+1)/2\n",
    "    im = torch.permute(im[0],(1,2,0)).detach().cpu()\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    #plt.imsave(im, \"dog1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, _  = gan([z], 0.7, c)\n",
    "show_gan_im(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_im = Image.open(\"/home/amildravid/bigGAN-DINO_swap/val_im/ILSVRC2012_val_00028617-_1_.jpg\")\n",
    "#real_im = Image.open(\"/home/amildravid/bigGAN-DINO_swap/golden_retriever/real/ILSVRC2012_val_00001112.jpg\")\n",
    "#real_im = Image.open(\"/home/amildravid/bigActivation_Matching/val_im/ILSVRC2012_val_00006981.jpg\")\n",
    "real_im = Image.open(\"/home/amildravid/activations_matching-main/activations_matching-main/misc/dogface_afhq.jpg\")\n",
    "#real_im = Image.open(\"/home/amildravid/bigGAN-DINO_swap/golden_retriever/sketch/sketch_7.jpg\")\n",
    "real_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_im = torchvision.transforms.ToTensor()(real_im).unsqueeze(0).to(device)\n",
    "#real_im = torchvision.transforms.RandomResizedCrop(256)(real_im)\n",
    "real_im = torch.nn.functional.interpolate(real_im, size = (512,512), mode = \"bicubic\")\n",
    "dino_real_im = torch.nn.functional.interpolate(real_im, size = (256,256), mode = \"bicubic\")\n",
    "dino_real_im = torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(dino_real_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.permute(real_im[0], (1,2,0)).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino(dino_real_im)\n",
    "dino_activs =  matching.store_activs(dino, dino_layers)\n",
    "#normalize\n",
    "eps = 0.00001\n",
    "for i,_ in enumerate(dino_activs):\n",
    "    dino_activs[i] = (dino_activs[i]-dino_stats[i][0])/(dino_stats[i][1]+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_perfect_activs = []\n",
    "for idx in dino_perfect_matches:\n",
    "    dino_perfect_activs.append(dino_activs[idx[0]][:,idx[1],:,:].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([z], lr=0.01, betas=(0.5, 0.999))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1000):\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    sample = gan(z,c)\n",
    "    im = (sample+1)/2\n",
    "    \n",
    "    \n",
    "    loss = torch.mean((im-real_im)**2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"E:\", epoch+1, \"loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    show_gan_im(sample)\n",
    "    \n",
    "    \n",
    "    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n",
    "    im = (im+1)/2\n",
    "    \n",
    "    \n",
    "    if epoch<=9:\n",
    "        file_name = \"00\"+str(epoch)+\".png\"\n",
    "    elif epoch<=99:\n",
    "        file_name = \"0\"+str(epoch)+\".png\"\n",
    "    else: \n",
    "        file_name = str(epoch)+\".png\"\n",
    "    \n",
    "    #plt.imsave(\"/home/amildravid/bigGAN-DINO_swap/morph/ex1/im/\"+file_name, im)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([z], lr=0.01, betas=(0.5, 0.999))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1000):\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    sample = gan(z,c)\n",
    "    \n",
    "    \n",
    "    \n",
    "    gan_activs = matching.store_activs(gan, gan_layers)\n",
    "    \n",
    "    \n",
    "    #normalize all activations\n",
    "    eps = 0.00001\n",
    "    for i,_ in enumerate(gan_activs):\n",
    "        gan_activs[i] = (gan_activs[i]-gan_stats[i][0])/(gan_stats[i][1]+eps)\n",
    "        \n",
    "    \n",
    "    gan_perfect_activs = []\n",
    "    for idx in perfect_matches:\n",
    "        gan_perfect_activs.append(gan_activs[idx[0]][:,idx[1],:,:])\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    losses = []\n",
    "    for i, _ in enumerate(gan_perfect_activs): \n",
    "        map_size = max((gan_perfect_activs[i].shape[1], dino_perfect_activs[i].shape[1]))\n",
    "        gan_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(gan_perfect_activs[i].unsqueeze(0))\n",
    "        dino_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(dino_perfect_activs[i])   \n",
    "        #loss += torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)/(map_size**2)\n",
    "        prod = torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)\n",
    "        div1 = torch.sum(gan_activ_new**2)\n",
    "        div2 = torch.sum(dino_activ_new**2)\n",
    "        corr = prod/torch.sqrt(div1*div2)\n",
    "        loss += corr\n",
    "        losses.append(corr)\n",
    "        #loss += torch.mean((gan_activ_new-dino_activ_new)**2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    loss *= -1 \n",
    "    #regularization = 50*torch.mean((z-reg)**2)\n",
    "    #loss +=  regularization\n",
    "    print(\"E:\", epoch+1, \"loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    show_gan_im(sample)\n",
    "    im = (sample+1)/2\n",
    "    \n",
    "    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n",
    "    im = (im+1)/2\n",
    "    \n",
    "    \n",
    "    if epoch<=9:\n",
    "        file_name = \"00\"+str(epoch)+\".png\"\n",
    "    elif epoch<=99:\n",
    "        file_name = \"0\"+str(epoch)+\".png\"\n",
    "    else: \n",
    "        file_name = str(epoch)+\".png\"\n",
    "    \n",
    "    #plt.imsave(\"/home/amildravid/bigGAN-DINO_swap/morph/ex1/im/\"+file_name, im)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([z], lr=0.01, betas=(0.5, 0.999))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1000):\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    sample = gan(z,c)\n",
    "    \n",
    "    im = (sample+1)/2\n",
    "    pixel_loss = torch.mean((im-real_im)**2)\n",
    "    \n",
    "    \n",
    "    print(pixel_loss)\n",
    "    \n",
    "    \n",
    "    gan_activs = matching.store_activs(gan, gan_layers)\n",
    "    \n",
    "    \n",
    "    #normalize all activations\n",
    "    eps = 0.00001\n",
    "    for i,_ in enumerate(gan_activs):\n",
    "        gan_activs[i] = (gan_activs[i]-gan_stats[i][0])/(gan_stats[i][1]+eps)\n",
    "        \n",
    "    \n",
    "    gan_perfect_activs = []\n",
    "    for idx in perfect_matches:\n",
    "        gan_perfect_activs.append(gan_activs[idx[0]][:,idx[1],:,:])\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    losses = []\n",
    "    for i, _ in enumerate(gan_perfect_activs): \n",
    "        map_size = max((gan_perfect_activs[i].shape[1], dino_perfect_activs[i].shape[1]))\n",
    "        gan_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(gan_perfect_activs[i].unsqueeze(0))\n",
    "        dino_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(dino_perfect_activs[i])   \n",
    "        #loss += torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)/(map_size**2)\n",
    "        prod = torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)\n",
    "        div1 = torch.sum(gan_activ_new**2)\n",
    "        div2 = torch.sum(dino_activ_new**2)\n",
    "        corr = prod/torch.sqrt(div1*div2)\n",
    "        loss += corr\n",
    "        losses.append(corr)\n",
    "        #loss += torch.mean((gan_activ_new-dino_activ_new)**2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    loss *= -1 \n",
    "    print(loss)\n",
    "    loss += 100*pixel_loss\n",
    "    \n",
    "    \n",
    "    #regularization = 100*torch.mean((z-reg)**2)\n",
    "    #loss +=  regularization\n",
    "    print(\"E:\", epoch+1, \"loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    show_gan_im(sample)\n",
    "    im = (sample+1)/2\n",
    "    \n",
    "    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n",
    "    im = (im+1)/2\n",
    "    \n",
    "    \n",
    "    if epoch<=9:\n",
    "        file_name = \"00\"+str(epoch)+\".png\"\n",
    "    elif epoch<=99:\n",
    "        file_name = \"0\"+str(epoch)+\".png\"\n",
    "    else: \n",
    "        file_name = str(epoch)+\".png\"\n",
    "    \n",
    "    #plt.imsave(\"/home/amildravid/bigGAN-DINO_swap/morph/ex1/im/\"+file_name, im)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W-Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = gan.model.mapping.w_avg.clone().unsqueeze(0)#torch.randn((1,512)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Variable(w1.clone(), requires_grad=True)\n",
    "optim = torch.optim.Adam([w], lr=0.01, betas=(0.5, 0.999))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.model.num_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_im = (gan.model.synthesis(w[0].repeat(1,16,1))+1)/2 \n",
    "plt.imshow(torch.permute(init_im[0].detach().cpu(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1000):\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    sample = gan.model.synthesis(w[0].repeat(1,16,1))\n",
    "    im = (sample+1)/2\n",
    "    \n",
    "    \n",
    "    loss = torch.mean((im-real_im)**2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"E:\", epoch+1, \"loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    show_gan_im(sample)\n",
    "    \n",
    "    \n",
    "    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n",
    "    im = (im+1)/2\n",
    "    \n",
    "    \n",
    "    if epoch<=9:\n",
    "        file_name = \"00\"+str(epoch)+\".png\"\n",
    "    elif epoch<=99:\n",
    "        file_name = \"0\"+str(epoch)+\".png\"\n",
    "    else: \n",
    "        file_name = str(epoch)+\".png\"\n",
    "    \n",
    "    #plt.imsave(\"/home/amildravid/bigGAN-DINO_swap/morph/ex1/im/\"+file_name, im)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Variable(w1.clone(), requires_grad=True)\n",
    "optim = torch.optim.Adam([w], lr=0.01, betas=(0.5, 0.999))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1000):\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    sample = gan.model.synthesis(w[0].repeat(1,16,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    gan_activs = matching.store_activs(gan, gan_layers)\n",
    "    \n",
    "    \n",
    "    #normalize all activations\n",
    "    eps = 0.00001\n",
    "    for i,_ in enumerate(gan_activs):\n",
    "        gan_activs[i] = (gan_activs[i]-gan_stats[i][0])/(gan_stats[i][1]+eps)\n",
    "        \n",
    "    \n",
    "    gan_perfect_activs = []\n",
    "    for idx in perfect_matches:\n",
    "        gan_perfect_activs.append(gan_activs[idx[0]][:,idx[1],:,:])\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    losses = []\n",
    "    for i, _ in enumerate(gan_perfect_activs): \n",
    "        map_size = max((gan_perfect_activs[i].shape[1], dino_perfect_activs[i].shape[1]))\n",
    "        gan_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(gan_perfect_activs[i].unsqueeze(0))\n",
    "        dino_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(dino_perfect_activs[i])   \n",
    "        #loss += torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)/(map_size**2)\n",
    "        prod = torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)\n",
    "        div1 = torch.sum(gan_activ_new**2)\n",
    "        div2 = torch.sum(dino_activ_new**2)\n",
    "        corr = prod/torch.sqrt(div1*div2)\n",
    "        loss += corr\n",
    "        losses.append(corr)\n",
    "        #loss += torch.mean((gan_activ_new-dino_activ_new)**2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    loss *= -1 \n",
    "    #regularization = 50*torch.mean((z-reg)**2)\n",
    "    #loss +=  regularization\n",
    "    print(\"E:\", epoch+1, \"loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    show_gan_im(sample)\n",
    "    im = (sample+1)/2\n",
    "    \n",
    "    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n",
    "    im = (im+1)/2\n",
    "    \n",
    "    \n",
    "    if epoch<=9:\n",
    "        file_name = \"00\"+str(epoch)+\".png\"\n",
    "    elif epoch<=99:\n",
    "        file_name = \"0\"+str(epoch)+\".png\"\n",
    "    else: \n",
    "        file_name = str(epoch)+\".png\"\n",
    "    \n",
    "    #plt.imsave(\"/home/amildravid/bigGAN-DINO_swap/morph/ex1/im/\"+file_name, im)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Variable(w1.clone(), requires_grad=True)\n",
    "optim = torch.optim.Adam([w], lr=0.01, betas=(0.5, 0.999))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,1000):\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    sample = gan.model.synthesis(w[0].repeat(1,16,1))\n",
    "    \n",
    "    im = (sample+1)/2\n",
    "    pixel_loss = torch.mean((im-real_im)**2)\n",
    "    \n",
    "    \n",
    "    print(pixel_loss)\n",
    "    \n",
    "    \n",
    "    gan_activs = matching.store_activs(gan, gan_layers)\n",
    "    \n",
    "    \n",
    "    #normalize all activations\n",
    "    eps = 0.00001\n",
    "    for i,_ in enumerate(gan_activs):\n",
    "        gan_activs[i] = (gan_activs[i]-gan_stats[i][0])/(gan_stats[i][1]+eps)\n",
    "        \n",
    "    \n",
    "    gan_perfect_activs = []\n",
    "    for idx in perfect_matches:\n",
    "        gan_perfect_activs.append(gan_activs[idx[0]][:,idx[1],:,:])\n",
    "    \n",
    "    \n",
    "    loss = 0\n",
    "    losses = []\n",
    "    for i, _ in enumerate(gan_perfect_activs): \n",
    "        map_size = max((gan_perfect_activs[i].shape[1], dino_perfect_activs[i].shape[1]))\n",
    "        gan_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(gan_perfect_activs[i].unsqueeze(0))\n",
    "        dino_activ_new = torch.nn.Upsample(size=(map_size,map_size), mode='bilinear')(dino_perfect_activs[i])   \n",
    "        #loss += torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)/(map_size**2)\n",
    "        prod = torch.einsum('aixy,ajxy->ij', gan_activ_new,dino_activ_new)\n",
    "        div1 = torch.sum(gan_activ_new**2)\n",
    "        div2 = torch.sum(dino_activ_new**2)\n",
    "        corr = prod/torch.sqrt(div1*div2)\n",
    "        loss += corr\n",
    "        losses.append(corr)\n",
    "        #loss += torch.mean((gan_activ_new-dino_activ_new)**2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    loss *= -1 \n",
    "    print(loss)\n",
    "    loss += 100*pixel_loss\n",
    "    \n",
    "    \n",
    "    #regularization = 100*torch.mean((z-reg)**2)\n",
    "    #loss +=  regularization\n",
    "    print(\"E:\", epoch+1, \"loss:\", loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    show_gan_im(sample)\n",
    "    im = (sample+1)/2\n",
    "    \n",
    "    im = torch.permute(sample[0],(1,2,0)).detach().cpu().numpy()\n",
    "    im = (im+1)/2\n",
    "    \n",
    "    \n",
    "    if epoch<=9:\n",
    "        file_name = \"00\"+str(epoch)+\".png\"\n",
    "    elif epoch<=99:\n",
    "        file_name = \"0\"+str(epoch)+\".png\"\n",
    "    else: \n",
    "        file_name = str(epoch)+\".png\"\n",
    "    \n",
    "    #plt.imsave(\"/home/amildravid/bigGAN-DINO_swap/morph/ex1/im/\"+file_name, im)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_im = (gan.model.synthesis(w[0].repeat(1,16,1))+1)/2 \n",
    "plt.imshow(torch.permute(init_im[0].detach().cpu(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((1,512)).to(device)\n",
    "x[:,0] = 1\n",
    "w_new = w+5*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_im = (gan.model.synthesis(w_new[0].repeat(1,16,1))+1)/2 \n",
    "plt.imshow(torch.permute(init_im[0].detach().cpu(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
